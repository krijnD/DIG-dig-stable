{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# GNNExplainer on BA-Shapes dataset for 2-layer GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/shurui.gui/anaconda3/envs/torch_110/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from dig.xgraph.dataset import SynGraphDataset\n",
    "from dig.xgraph.models import *\n",
    "from dig.xgraph.utils.compatibility import compatible_state_dict\n",
    "from dig.xgraph.utils.init import fix_random_seed\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def index_to_mask(index, size):\n",
    "    mask = torch.zeros(size, dtype=torch.bool, device=index.device)\n",
    "    mask[index] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "def split_dataset(dataset):\n",
    "    indices = []\n",
    "    num_classes = 4\n",
    "    train_percent = 0.7\n",
    "    for i in range(num_classes):\n",
    "        index = (dataset.data.y == i).nonzero().view(-1)\n",
    "        index = index[torch.randperm(index.size(0))]\n",
    "        indices.append(index)\n",
    "\n",
    "    train_index = torch.cat([i[:int(len(i) * train_percent)] for i in indices], dim=0)\n",
    "\n",
    "    rest_index = torch.cat([i[int(len(i) * train_percent):] for i in indices], dim=0)\n",
    "    rest_index = rest_index[torch.randperm(rest_index.size(0))]\n",
    "\n",
    "    dataset.data.train_mask = index_to_mask(train_index, size=dataset.data.num_nodes)\n",
    "    dataset.data.val_mask = index_to_mask(rest_index[:len(rest_index) // 2], size=dataset.data.num_nodes)\n",
    "    dataset.data.test_mask = index_to_mask(rest_index[len(rest_index) // 2:], size=dataset.data.num_nodes)\n",
    "\n",
    "    dataset.data, dataset.slices = dataset.collate([dataset.data])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "fix_random_seed(123)\n",
    "dataset = SynGraphDataset('./datasets', 'BA_shapes')\n",
    "dataset.data.x = dataset.data.x.to(torch.float32)\n",
    "dataset.data.x = dataset.data.x[:, :1]\n",
    "dim_node = dataset.num_node_features\n",
    "dim_edge = dataset.num_edge_features\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "splitted_dataset = split_dataset(dataset)\n",
    "splitted_dataset.data.mask = splitted_dataset.data.test_mask\n",
    "dataloader = DataLoader(splitted_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load model and checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_checkpoints(root='./'):\n",
    "    if osp.exists(osp.join(root, 'checkpoints')):\n",
    "        return\n",
    "    url = ('https://github.com/divelab/DIG_storage/raw/main/xgraph/checkpoints.zip')\n",
    "    path = download_url(url, root)\n",
    "    extract_zip(path, root)\n",
    "    os.unlink(path)\n",
    "\n",
    "\n",
    "model = GIN_2l(model_level='node', dim_node=dim_node, dim_hidden=300, num_classes=num_classes)\n",
    "model.to(device)\n",
    "check_checkpoints()\n",
    "ckpt_path = osp.join('checkpoints', 'ba_shapes', 'GIN_2l', '0', 'GIN_2l_best.ckpt')\n",
    "state_dict = compatible_state_dict(torch.load(ckpt_path, map_location='cpu')['state_dict'])\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Display example output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dig.xgraph.method import GNNExplainer\n",
    "\n",
    "explainer = GNNExplainer(model, epochs=100, lr=0.01, explain_graph=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# --- Set the Sparsity to 0.5 ---\n",
    "sparsity = 0.5\n",
    "\n",
    "# --- Create data collector and explanation processor ---\n",
    "from dig.xgraph.evaluation import XCollector\n",
    "\n",
    "x_collector = XCollector(sparsity)\n",
    "# x_processor = ExplanationProcessor(model=model, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run explainer on the given model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explain graph 0 node 5\n",
      "explain graph 0 node 14\n",
      "explain graph 0 node 21\n",
      "explain graph 0 node 22\n",
      "explain graph 0 node 27\n",
      "explain graph 0 node 29\n",
      "explain graph 0 node 36\n",
      "explain graph 0 node 38\n",
      "explain graph 0 node 41\n",
      "explain graph 0 node 46\n",
      "explain graph 0 node 51\n",
      "explain graph 0 node 58\n",
      "explain graph 0 node 77\n",
      "explain graph 0 node 91\n",
      "explain graph 0 node 97\n",
      "explain graph 0 node 99\n",
      "explain graph 0 node 103\n",
      "explain graph 0 node 106\n",
      "explain graph 0 node 116\n",
      "explain graph 0 node 117\n",
      "explain graph 0 node 118\n",
      "explain graph 0 node 130\n",
      "explain graph 0 node 133\n",
      "explain graph 0 node 134\n",
      "explain graph 0 node 136\n",
      "explain graph 0 node 140\n",
      "explain graph 0 node 145\n",
      "explain graph 0 node 167\n",
      "explain graph 0 node 172\n",
      "explain graph 0 node 176\n",
      "explain graph 0 node 191\n",
      "explain graph 0 node 192\n",
      "explain graph 0 node 198\n",
      "explain graph 0 node 199\n",
      "explain graph 0 node 200\n",
      "explain graph 0 node 209\n",
      "explain graph 0 node 224\n",
      "explain graph 0 node 229\n",
      "explain graph 0 node 235\n",
      "explain graph 0 node 237\n",
      "explain graph 0 node 244\n",
      "explain graph 0 node 249\n",
      "explain graph 0 node 260\n",
      "explain graph 0 node 267\n",
      "explain graph 0 node 269\n",
      "explain graph 0 node 279\n",
      "explain graph 0 node 281\n",
      "explain graph 0 node 303\n",
      "explain graph 0 node 309\n",
      "explain graph 0 node 314\n",
      "explain graph 0 node 320\n",
      "explain graph 0 node 327\n",
      "explain graph 0 node 328\n",
      "explain graph 0 node 333\n",
      "explain graph 0 node 341\n",
      "explain graph 0 node 347\n",
      "explain graph 0 node 350\n",
      "explain graph 0 node 374\n",
      "explain graph 0 node 376\n",
      "explain graph 0 node 390\n",
      "explain graph 0 node 410\n",
      "explain graph 0 node 414\n",
      "explain graph 0 node 428\n",
      "explain graph 0 node 435\n",
      "explain graph 0 node 436\n",
      "explain graph 0 node 454\n",
      "explain graph 0 node 467\n",
      "explain graph 0 node 471\n",
      "explain graph 0 node 479\n",
      "explain graph 0 node 484\n",
      "explain graph 0 node 495\n",
      "explain graph 0 node 510\n",
      "explain graph 0 node 520\n",
      "explain graph 0 node 531\n",
      "explain graph 0 node 535\n",
      "explain graph 0 node 544\n",
      "explain graph 0 node 549\n",
      "explain graph 0 node 556\n",
      "explain graph 0 node 560\n",
      "explain graph 0 node 564\n",
      "explain graph 0 node 566\n",
      "explain graph 0 node 573\n",
      "explain graph 0 node 577\n",
      "explain graph 0 node 582\n",
      "explain graph 0 node 587\n",
      "explain graph 0 node 598\n",
      "explain graph 0 node 605\n",
      "explain graph 0 node 608\n",
      "explain graph 0 node 615\n",
      "explain graph 0 node 616\n",
      "explain graph 0 node 620\n",
      "explain graph 0 node 622\n",
      "explain graph 0 node 627\n",
      "explain graph 0 node 632\n",
      "explain graph 0 node 633\n",
      "explain graph 0 node 634\n",
      "explain graph 0 node 638\n",
      "explain graph 0 node 642\n",
      "explain graph 0 node 649\n",
      "explain graph 0 node 659\n"
     ]
    }
   ],
   "source": [
    "index = -1\n",
    "for i, data in enumerate(dataloader):\n",
    "    for j, node_idx in enumerate(torch.where(data.test_mask == True)[0]):\n",
    "        index += 1\n",
    "        print(f'explain graph {i} node {node_idx}')\n",
    "        data.to(device)\n",
    "\n",
    "        if torch.isnan(data.y[0].squeeze()):\n",
    "            continue\n",
    "\n",
    "        edge_masks, hard_edge_masks, related_preds = explainer(data.x, data.edge_index, sparsity=sparsity, num_classes=num_classes, node_idx=node_idx)\n",
    "\n",
    "        x_collector.collect_data(hard_edge_masks, related_preds, data.y[0].squeeze().long().item())\n",
    "        # if you only have the edge masks without related_pred, please feed sparsity controlled mask to\n",
    "        # obtain the result: x_processor(data, masks, x_collector)\n",
    "        if index >= 99:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Output metrics evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity: 0.4682\n",
      "Fidelity_inv: -0.0002\n",
      "Sparsity: 0.5000\n"
     ]
    }
   ],
   "source": [
    "print(f'Fidelity: {x_collector.fidelity:.4f}\\n'\n",
    "      f'Fidelity_inv: {x_collector.fidelity_inv:.4f}\\n'\n",
    "      f'Sparsity: {x_collector.sparsity:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
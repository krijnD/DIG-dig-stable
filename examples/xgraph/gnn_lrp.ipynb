{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GNN-LRP on BA-LRP dataset for GCN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/shurui.gui/anaconda3/envs/torch_110/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from dig.xgraph.dataset import BA_LRP\n",
    "from dig.xgraph.models import GCN_3l\n",
    "from dig.xgraph.utils.compatibility import compatible_state_dict\n",
    "from dig.xgraph.utils.init import fix_random_seed\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def split_dataset(dataset, dataset_split=(0.8, 0.1, 0.1)):\n",
    "    dataset_len = len(dataset)\n",
    "    dataset_split = [int(dataset_len * dataset_split[0]),\n",
    "                     int(dataset_len * dataset_split[1]),\n",
    "                     0]\n",
    "    dataset_split[2] = dataset_len - dataset_split[0] - dataset_split[1]\n",
    "    train_set, val_set, test_set = random_split(dataset, dataset_split)\n",
    "\n",
    "    return {'train': train_set, 'val': val_set, 'test': test_set}\n",
    "\n",
    "\n",
    "fix_random_seed(123)\n",
    "dataset = BA_LRP('datasets')\n",
    "\n",
    "dataset.data.x = dataset.data.x.to(torch.float32)\n",
    "dataset.data.y = dataset.data.y[:, 0]\n",
    "dim_node = dataset.num_node_features\n",
    "dim_edge = dataset.num_edge_features\n",
    "num_targets = dataset.num_classes\n",
    "num_classes = 2\n",
    "\n",
    "splitted_dataset = split_dataset(dataset)\n",
    "dataloader = DataLoader(splitted_dataset['test'], batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load model and checkpoints"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_checkpoints(root='./'):\n",
    "    if osp.exists(osp.join(root, 'checkpoints')):\n",
    "        return\n",
    "    url = ('https://github.com/divelab/DIG_storage/raw/main/xgraph/checkpoints.zip')\n",
    "    path = download_url(url, root)\n",
    "    extract_zip(path, root)\n",
    "    os.unlink(path)\n",
    "\n",
    "\n",
    "model = GCN_3l(model_level='graph', dim_node=dim_node, dim_hidden=300, num_classes=num_classes)\n",
    "model.to(device)\n",
    "check_checkpoints()\n",
    "ckpt_path = osp.join('checkpoints', 'ba_lrp', 'GCN_3l', '0', 'GCN_3l_best.ckpt')\n",
    "state_dict = compatible_state_dict(torch.load(ckpt_path, map_location='cpu')['state_dict'])\n",
    "model.load_state_dict(state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display example output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.5759,  2.6295]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = list(dataloader)[0].to(device)\n",
    "out = model(data.x, data.edge_index)\n",
    "print(out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the explainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from dig.xgraph.method import GNN_LRP\n",
    "\n",
    "explainer = GNN_LRP(model, explain_graph=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup for evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# --- Set the Sparsity to 0. ---\n",
    "sparsity = 0.5\n",
    "\n",
    "# --- Create data collector and explanation processor ---\n",
    "from dig.xgraph.evaluation import XCollector\n",
    "\n",
    "x_collector = XCollector(sparsity)\n",
    "# x_processor = ExplanationProcessor(model=model, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run explainer on the given model and dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explain graph line 4835\n",
      "explain graph line 3443\n",
      "explain graph line 14435\n",
      "explain graph line 6575\n",
      "explain graph line 1521\n",
      "explain graph line 2454\n",
      "explain graph line 2551\n",
      "explain graph line 15026\n",
      "explain graph line 14862\n",
      "explain graph line 18955\n",
      "explain graph line 16517\n",
      "explain graph line 4866\n",
      "explain graph line 17951\n",
      "explain graph line 7567\n",
      "explain graph line 6920\n",
      "explain graph line 14567\n",
      "explain graph line 2847\n",
      "explain graph line 11472\n",
      "explain graph line 13305\n",
      "explain graph line 6961\n",
      "explain graph line 18725\n",
      "explain graph line 13531\n",
      "explain graph line 12320\n",
      "explain graph line 2744\n",
      "explain graph line 19356\n",
      "explain graph line 14045\n",
      "explain graph line 17569\n",
      "explain graph line 5872\n",
      "explain graph line 11646\n",
      "explain graph line 4492\n",
      "explain graph line 17075\n",
      "explain graph line 9038\n",
      "explain graph line 17290\n",
      "explain graph line 64\n",
      "explain graph line 974\n",
      "explain graph line 17241\n",
      "explain graph line 693\n",
      "explain graph line 779\n",
      "explain graph line 7396\n",
      "explain graph line 18414\n",
      "explain graph line 3176\n",
      "explain graph line 16552\n",
      "explain graph line 18330\n",
      "explain graph line 3255\n",
      "explain graph line 2381\n",
      "explain graph line 13313\n",
      "explain graph line 7005\n",
      "explain graph line 11612\n",
      "explain graph line 3148\n",
      "explain graph line 18305\n",
      "explain graph line 622\n",
      "explain graph line 11668\n",
      "explain graph line 18875\n",
      "explain graph line 10511\n",
      "explain graph line 1359\n",
      "explain graph line 11703\n",
      "explain graph line 18742\n",
      "explain graph line 15040\n",
      "explain graph line 6021\n",
      "explain graph line 12193\n",
      "explain graph line 13864\n",
      "explain graph line 9279\n",
      "explain graph line 2750\n",
      "explain graph line 14981\n",
      "explain graph line 19178\n",
      "explain graph line 19741\n",
      "explain graph line 12141\n",
      "explain graph line 6406\n",
      "explain graph line 7401\n",
      "explain graph line 7716\n",
      "explain graph line 17132\n",
      "explain graph line 6218\n",
      "explain graph line 6224\n",
      "explain graph line 15251\n",
      "explain graph line 9418\n",
      "explain graph line 853\n",
      "explain graph line 5746\n",
      "explain graph line 2669\n",
      "explain graph line 11760\n",
      "explain graph line 539\n",
      "explain graph line 13596\n",
      "explain graph line 730\n",
      "explain graph line 15001\n",
      "explain graph line 9393\n",
      "explain graph line 13932\n",
      "explain graph line 12060\n",
      "explain graph line 10480\n",
      "explain graph line 3698\n",
      "explain graph line 1162\n",
      "explain graph line 3168\n",
      "explain graph line 5901\n",
      "explain graph line 1026\n",
      "explain graph line 4040\n",
      "explain graph line 10120\n",
      "explain graph line 12448\n",
      "explain graph line 4891\n",
      "explain graph line 8069\n",
      "explain graph line 1734\n",
      "explain graph line 16740\n",
      "explain graph line 13500\n"
     ]
    }
   ],
   "source": [
    "for index, data in enumerate(dataloader):\n",
    "    print(f'explain graph line {dataloader.dataset.indices[index] + 2}')\n",
    "    data.to(device)\n",
    "\n",
    "    if torch.isnan(data.y[0].squeeze()):\n",
    "        continue\n",
    "\n",
    "    walks, masks, related_preds = explainer(data.x, data.edge_index, sparsity=sparsity, num_classes=num_classes)\n",
    "\n",
    "    x_collector.collect_data(masks, related_preds, data.y[0].squeeze().long().item())\n",
    "\n",
    "    # if you only have the edge masks without related_pred, please feed sparsity controlled mask to\n",
    "    # obtain the result: x_processor(data, masks, x_collector)\n",
    "\n",
    "    if index >= 99:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Output metrics evaluation results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity: 0.5191\n",
      "Fidelity_inv: 0.1258\n",
      "Sparsity: 0.5000\n"
     ]
    }
   ],
   "source": [
    "print(f'Fidelity: {x_collector.fidelity:.4f}\\n'\n",
    "      f'Fidelity_inv: {x_collector.fidelity_inv:.4f}\\n'\n",
    "      f'Sparsity: {x_collector.sparsity:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for sslgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this hand-on code tutorial, we will show how to reproduce and develop self-supervised learning (SSL) methods using our DIG library. Specifically, we show how to implement existing SSL methods, how to develop and evaluate your own methods, and how to extract embeddings generated by SSL methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementation of existing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dig.sslgraph.utils import Encoder\n",
    "from dig.sslgraph.dataset import get_dataset, get_node_dataset\n",
    "from dig.sslgraph.evaluation import GraphUnsupervised, NodeUnsupervised, GraphSemisupervised\n",
    "from dig.sslgraph.method import InfoGraph, MVGRL, GRACE, GraphCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 Unsupervised learning -- graph level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to download a graph level dataset, define a model, and then evaluate following our standard evluation process. Here we show two examples of unsupervised graph level tasks by existing methods, InfoGraph and MVGRL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 20: 100%|█████████████████████████████| 20/20 [05:47<00:00, 17.37s/it, loss=0.044081]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch 20: acc 0.8936 +/-(0.0555)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8935672514619883, 0.05553332204466091)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = get_dataset('MUTAG', task='unsupervised')\n",
    "\n",
    "embed_dim = 512\n",
    "encoder = Encoder(feat_dim=dataset[0].x.shape[1], hidden_dim=embed_dim, \n",
    "                  n_layers=4, gnn='gin', node_level=True)\n",
    "infograph = InfoGraph(g_dim=embed_dim*4, n_dim=embed_dim)\n",
    "\n",
    "evaluator = GraphUnsupervised(dataset, log_interval=1)\n",
    "evaluator.setup_train_config(batch_size=256, p_lr=0.0001, p_epoch=20)\n",
    "evaluator.evaluate(learning_model=infograph, encoder=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 20: 100%|████████████████████████████| 20/20 [00:53<00:00,  2.67s/it, loss=-0.021439]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch 18: acc 0.8991 +/-(0.0981)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.899122807017544, 0.09813851723297315)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = get_dataset('MUTAG', task='unsupervised')\n",
    "\n",
    "embed_dim = 512\n",
    "encoder_adj = Encoder(feat_dim=dataset[0].x.shape[1], hidden_dim=embed_dim, \n",
    "                      n_layers=4, gnn='gcn', node_level=True, act='prelu')\n",
    "encoder_diff = Encoder(feat_dim=dataset[0].x.shape[1], hidden_dim=embed_dim, \n",
    "                       n_layers=4, gnn='gcn', node_level=True, act='prelu', edge_weight=True)\n",
    "mvgrl = MVGRL(g_dim=embed_dim*4, n_dim=embed_dim, diffusion_type='ppr', device=7)\n",
    "\n",
    "evaluator = GraphUnsupervised(dataset, log_interval=2, device=7)\n",
    "evaluator.setup_train_config(batch_size=256, p_lr=0.001, p_epoch=20)\n",
    "evaluator.evaluate(learning_model=mvgrl, encoder=[encoder_adj, encoder_diff])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Unsupervised learning -- node level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to download a node level dataset, define a model, and then evaluate following our standard evluation process. Here we show one example of unsupervised node level task by an existing method GRACE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 2000: 100%|███████████████████████| 2000/2000 [07:47<00:00,  4.28it/s, loss=7.770879]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch 1300: acc 0.8249 (+/- 0.0048).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8249000310897827"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = get_node_dataset('cora')\n",
    "\n",
    "embed_dim = 128\n",
    "encoder = Encoder(feat_dim=dataset[0].x.shape[1], hidden_dim=embed_dim, \n",
    "                  n_layers=2, gnn='gcn', node_level=True, graph_level=False)\n",
    "grace = GRACE(dim=embed_dim, dropE_rate_1=0.2, dropE_rate_2=0.4, \n",
    "              maskN_rate_1=0.3, maskN_rate_2=0.4, tau=0.4, device=3)\n",
    "\n",
    "evaluator = NodeUnsupervised(dataset, device=3, log_interval=100)\n",
    "evaluator.setup_train_config(p_lr=0.0005, p_epoch=2000, p_weight_decay=1e-5, comp_embed_on='cpu')\n",
    "evaluator.evaluate(learning_model=grace, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Semi-supervised learning -- graph level & grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to download a graph level dataset in semisupervised mode, define a model, and then evaluate following our standard evluation process. Here we show one example of semi-supervised graph level task by an existing methods GraphCL. For semi-supervised setting, GraphCL uses ResGCN. Available augmentation includes: dropN, maskN, permE, subgraph, random[2-4]. In this example, we use a label rate of 10%. You can also perform evaluation with grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 100: 100%|██████████████████████████| 100/100 [09:48<00:00,  5.88s/it, loss=2.847807]\n",
      "Fold 1, finetuning: 100%|████████████████| 100/100 [00:12<00:00,  8.11it/s, acc=0.7119, val_loss=1.6124]\n",
      "Fold 2, finetuning: 100%|████████████████| 100/100 [00:11<00:00,  8.68it/s, acc=0.7797, val_loss=0.7528]\n",
      "Fold 3, finetuning: 100%|████████████████| 100/100 [00:11<00:00,  8.48it/s, acc=0.7119, val_loss=1.3771]\n",
      "Fold 4, finetuning: 100%|████████████████| 100/100 [00:11<00:00,  8.56it/s, acc=0.7797, val_loss=0.8696]\n",
      "Fold 5, finetuning: 100%|████████████████| 100/100 [00:11<00:00,  8.87it/s, acc=0.7458, val_loss=1.1965]\n",
      "Fold 6, finetuning: 100%|████████████████| 100/100 [00:12<00:00,  8.25it/s, acc=0.7542, val_loss=1.1717]\n",
      "Fold 7, finetuning: 100%|████████████████| 100/100 [00:12<00:00,  7.96it/s, acc=0.7542, val_loss=1.2606]\n",
      "Fold 8, finetuning: 100%|████████████████| 100/100 [00:11<00:00,  8.49it/s, acc=0.7203, val_loss=1.2794]\n",
      "Fold 9, finetuning: 100%|████████████████| 100/100 [00:11<00:00,  8.34it/s, acc=0.6667, val_loss=1.6173]\n",
      "Fold 10, finetuning: 100%|███████████████| 100/100 [00:13<00:00,  7.69it/s, acc=0.6752, val_loss=1.2761]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7699044942855835, 0.03682943806052208)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, dataset_pretrain = get_dataset('DD', task='semisupervised')\n",
    "feat_dim = dataset[0].x.shape[1]\n",
    "embed_dim = 128\n",
    "\n",
    "encoder = Encoder(feat_dim, embed_dim, n_layers=3, gnn='resgcn')\n",
    "graphcl = GraphCL(embed_dim, aug_1='subgraph', aug_2='dropN')\n",
    "\n",
    "evaluator = GraphSemisupervised(dataset, dataset_pretrain, label_rate=0.1)\n",
    "evaluator.evaluate(learning_model=graphcl, encoder=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 20: 100%|████████████████████| 20/20 [01:41<00:00,  5.06s/it, loss=3.040437]\n",
      "Fold 1, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.93it/s, acc=0.6949, val_loss=1.5951]\n",
      "Fold 2, finetuning: 100%|███████| 100/100 [00:07<00:00, 13.15it/s, acc=0.7712, val_loss=0.9050]\n",
      "Fold 3, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.80it/s, acc=0.7119, val_loss=1.5409]\n",
      "Fold 4, finetuning: 100%|███████| 100/100 [00:07<00:00, 13.13it/s, acc=0.7712, val_loss=0.8240]\n",
      "Fold 5, finetuning: 100%|███████| 100/100 [00:07<00:00, 13.09it/s, acc=0.7203, val_loss=1.2548]\n",
      "Fold 6, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.99it/s, acc=0.7966, val_loss=1.1412]\n",
      "Fold 7, finetuning: 100%|███████| 100/100 [00:08<00:00, 12.40it/s, acc=0.8136, val_loss=0.9092]\n",
      "Fold 8, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.58it/s, acc=0.6356, val_loss=1.6541]\n",
      "Fold 9, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.97it/s, acc=0.6154, val_loss=4.1965]\n",
      "Fold 10, finetuning: 100%|██████| 100/100 [00:07<00:00, 12.86it/s, acc=0.7692, val_loss=0.9628]\n",
      "Pretraining: epoch 40: 100%|████████████████████| 40/40 [03:27<00:00,  5.19s/it, loss=2.885464]\n",
      "Fold 1, finetuning: 100%|███████| 100/100 [00:07<00:00, 13.00it/s, acc=0.6525, val_loss=0.9769]\n",
      "Fold 2, finetuning: 100%|███████| 100/100 [00:07<00:00, 13.13it/s, acc=0.6695, val_loss=0.7380]\n",
      "Fold 3, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.55it/s, acc=0.7203, val_loss=0.8138]\n",
      "Fold 4, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.75it/s, acc=0.7627, val_loss=0.6905]\n",
      "Fold 5, finetuning: 100%|███████| 100/100 [00:07<00:00, 13.19it/s, acc=0.8051, val_loss=0.5426]\n",
      "Fold 6, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.94it/s, acc=0.7966, val_loss=0.5852]\n",
      "Fold 7, finetuning: 100%|███████| 100/100 [00:08<00:00, 12.38it/s, acc=0.8220, val_loss=0.5441]\n",
      "Fold 8, finetuning: 100%|███████| 100/100 [00:08<00:00, 12.08it/s, acc=0.6695, val_loss=1.2431]\n",
      "Fold 9, finetuning: 100%|███████| 100/100 [00:08<00:00, 12.33it/s, acc=0.6667, val_loss=1.1363]\n",
      "Fold 10, finetuning: 100%|██████| 100/100 [00:08<00:00, 11.88it/s, acc=0.7265, val_loss=0.6896]\n",
      "Pretraining: epoch 20: 100%|████████████████████| 20/20 [01:38<00:00,  4.93s/it, loss=3.045913]\n",
      "Fold 1, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.56it/s, acc=0.6525, val_loss=1.2434]\n",
      "Fold 2, finetuning: 100%|███████| 100/100 [00:08<00:00, 12.41it/s, acc=0.7034, val_loss=0.8522]\n",
      "Fold 3, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.83it/s, acc=0.7203, val_loss=0.8383]\n",
      "Fold 4, finetuning: 100%|███████| 100/100 [00:07<00:00, 13.08it/s, acc=0.7288, val_loss=0.6386]\n",
      "Fold 5, finetuning: 100%|███████| 100/100 [00:07<00:00, 13.56it/s, acc=0.7203, val_loss=0.8911]\n",
      "Fold 6, finetuning: 100%|███████| 100/100 [00:07<00:00, 13.19it/s, acc=0.7966, val_loss=0.7402]\n",
      "Fold 7, finetuning: 100%|███████| 100/100 [00:08<00:00, 12.16it/s, acc=0.8136, val_loss=0.6164]\n",
      "Fold 8, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.77it/s, acc=0.6610, val_loss=1.6025]\n",
      "Fold 9, finetuning: 100%|███████| 100/100 [00:07<00:00, 13.26it/s, acc=0.6752, val_loss=0.9115]\n",
      "Fold 10, finetuning: 100%|██████| 100/100 [00:08<00:00, 12.49it/s, acc=0.7521, val_loss=0.8067]\n",
      "Pretraining: epoch 40: 100%|████████████████████| 40/40 [03:24<00:00,  5.11s/it, loss=2.761854]\n",
      "Fold 1, finetuning: 100%|███████| 100/100 [00:08<00:00, 12.43it/s, acc=0.6780, val_loss=1.2360]\n",
      "Fold 2, finetuning: 100%|███████| 100/100 [00:07<00:00, 13.23it/s, acc=0.6949, val_loss=0.7448]\n",
      "Fold 3, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.97it/s, acc=0.7203, val_loss=0.8281]\n",
      "Fold 4, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.87it/s, acc=0.7542, val_loss=0.7769]\n",
      "Fold 5, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.70it/s, acc=0.7288, val_loss=0.8197]\n",
      "Fold 6, finetuning: 100%|███████| 100/100 [00:08<00:00, 11.95it/s, acc=0.7119, val_loss=0.7494]\n",
      "Fold 7, finetuning: 100%|███████| 100/100 [00:08<00:00, 11.84it/s, acc=0.7712, val_loss=0.6137]\n",
      "Fold 8, finetuning: 100%|███████| 100/100 [00:07<00:00, 12.78it/s, acc=0.6271, val_loss=1.9603]\n",
      "Fold 9, finetuning: 100%|███████| 100/100 [00:08<00:00, 11.78it/s, acc=0.6667, val_loss=0.8765]\n",
      "Fold 10, finetuning: 100%|██████| 100/100 [00:08<00:00, 12.37it/s, acc=0.7692, val_loss=0.9076]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paras: 20 epoch, lr=0.010000, acc=0.7623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7622699737548828, 0.048677004873752594, (0.01, 20))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.grid_search(learning_model=graphcl, encoder=encoder,\n",
    "                      p_lr_lst=[0.01,0.001], p_epoch_lst=[20,40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Develop & evaluate your own method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always write your own code to do flexible evlauation of the above defined contrastive methods. However, we provide pre-implemented evluation tools for more convenient evaluation. The tool works with most datasets from pytorch-geometric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 100: 100%|█████████████████████████| 100/100 [06:59<00:00,  4.20s/it, loss=-0.704380]\n",
      "Fold 1, finetuning: 100%|████████████████| 100/100 [00:20<00:00,  4.82it/s, acc=0.6375, val_loss=2.6667]\n",
      "Fold 2, finetuning: 100%|████████████████| 100/100 [00:21<00:00,  4.69it/s, acc=0.6448, val_loss=9.3357]\n",
      "Fold 3, finetuning: 100%|████████████████| 100/100 [00:20<00:00,  4.84it/s, acc=0.5474, val_loss=2.6623]\n",
      "Fold 4, finetuning: 100%|████████████████| 100/100 [00:20<00:00,  4.79it/s, acc=0.5888, val_loss=3.1011]\n",
      "Fold 5, finetuning: 100%|████████████████| 100/100 [00:21<00:00,  4.75it/s, acc=0.5937, val_loss=5.9771]\n",
      "Fold 6, finetuning: 100%|████████████████| 100/100 [00:20<00:00,  4.91it/s, acc=0.6715, val_loss=1.6416]\n",
      "Fold 7, finetuning: 100%|████████████████| 100/100 [00:20<00:00,  4.80it/s, acc=0.6204, val_loss=2.0579]\n",
      "Fold 8, finetuning: 100%|████████████████| 100/100 [00:20<00:00,  4.90it/s, acc=0.6277, val_loss=3.3737]\n",
      "Fold 9, finetuning: 100%|████████████████| 100/100 [00:21<00:00,  4.71it/s, acc=0.6472, val_loss=2.0004]\n",
      "Fold 10, finetuning: 100%|███████████████| 100/100 [00:21<00:00,  4.70it/s, acc=0.5620, val_loss=2.3573]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6204379796981812, 0.042001646012067795)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dig.sslgraph.method.contrastive.views_fn import NodeAttrMask\n",
    "from dig.sslgraph.method import Contrastive\n",
    "from dig.sslgraph.dataset import get_dataset\n",
    "from dig.sslgraph.utils import Encoder\n",
    "from dig.sslgraph.evaluation import GraphSemisupervised\n",
    "\n",
    "class SSLModel(Contrastive):\n",
    "    def __init__(self, z_dim, mask_ratio, **kwargs):\n",
    "\n",
    "        objective = \"JSE\"\n",
    "        proj=\"MLP\"\n",
    "        mask_i = NodeAttrMask(mask_ratio=mask_ratio)\n",
    "        mask_j = NodeAttrMask(mask_ratio=mask_ratio)\n",
    "        views_fn = [mask_i, mask_j]\n",
    "\n",
    "        super(SSLModel, self).__init__(objective=objective,\n",
    "                                    views_fn=views_fn,\n",
    "                                    z_dim=z_dim,\n",
    "                                    proj=proj,\n",
    "                                    node_level=False,\n",
    "                                    **kwargs)\n",
    "\n",
    "    def train(self, encoder, data_loader, optimizer, epochs, per_epoch_out=False):\n",
    "        for enc, proj in super(SSLModel, self).train(encoder, data_loader,\n",
    "                                                    optimizer, epochs, per_epoch_out):\n",
    "            yield enc\n",
    "\n",
    "dataset, dataset_pretrain = get_dataset('NCI1', task='semisupervised')\n",
    "feat_dim = dataset[0].x.shape[1]\n",
    "embed_dim = 128\n",
    "\n",
    "encoder = Encoder(feat_dim, embed_dim, n_layers=3, gnn='resgcn')\n",
    "ssl_model = SSLModel(z_dim=embed_dim, mask_ratio=0.1)\n",
    "evaluator = GraphSemisupervised(dataset, dataset_pretrain, label_rate=0.01)\n",
    "evaluator.evaluate(learning_model=ssl_model, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract embeddings for other tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also extract graph embeddings generated by exisisting SSL methods, and then apply the extracted graph embeddings to any other downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object InfoGraph.train at 0x7f5f80f7c510>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dig.sslgraph.dataset import get_dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "\n",
    "embed_dim = 512\n",
    "encoder = Encoder(feat_dim=dataset[0].x.shape[1], hidden_dim=embed_dim, \n",
    "                  n_layers=4, gnn='gin', node_level=True)\n",
    "infograph = InfoGraph(g_dim=embed_dim*4, n_dim=embed_dim)\n",
    "\n",
    "dataset = get_dataset('MUTAG', task='unsupervised')\n",
    "pretrain_dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=0.01, weight_decay=0)\n",
    "infograph.train(encoder, pretrain_dataloader, optimizer, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the embedding of the first graph in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = encoder(dataset[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
